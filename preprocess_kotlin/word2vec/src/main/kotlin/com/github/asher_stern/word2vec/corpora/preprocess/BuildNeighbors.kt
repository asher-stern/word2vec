package com.github.asher_stern.word2vec.corpora.preprocess


import com.github.asher_stern.word2vec.utilities._provide
import org.apache.commons.collections4.BidiMap
import org.apache.commons.collections4.bidimap.DualLinkedHashBidiMap
import java.io.File

/**
 * Created by Asher Stern on October-16 2017.
 */

const val UNKNOWN = "__UNKNOWN__"
const val OUTPUT_WORDS = false

/**
 * Entry point for [BuildNeighbors].
 * @param args arguments of [BuildNeighbors] primary constructor.
 */
fun main(args: Array<String>)
{
    args._provide {
        BuildNeighbors(File(arg), File(arg), arg.toInt(), File(arg), arg.toInt(), arg.toInt()).use { it.build() }
    }
}


/**
 * Generates a neighbors.txt file which contains word-context pairs.
 * This class should be used **after** [CorpusToTokensAndSentences] was executed and generated sentences.txt and words.txt.
 * The neighbors are based on sentences.txt and words.txt.
 *
 * Each line in neighbors.txt file is composed as : word, whitespace, word.
 * The constant [OUTPUT_WORDS] controls whether "word" is indeed word (if [OUTPUT_WORDS] = true), or word-ID (if [OUTPUT_WORDS] = false).
 * The word-ID is taken from words.txt file: the word appearing in line *N* (in words.txt) has word-ID *N*.
 * In each line, the second word (after the whitespace) is a context-word of the first word
 *
 * @param wordFile words.txt file generated by [CorpusToTokensAndSentences]
 * @param sentenceFile sentences.txt file generated by [CorpusToTokensAndSentences]
 * @param numberOfWords the number of most-common words to be used, for which neighbors will be generated. This number can
 * be large up to the number of words in words.txt file. But it can be smaller, to generate less data.
 * @param outputFile path of output file ("neighbors.txt")
 * @param windowSize controls which words are considered *context words* of a given word. Window-size of 1 means that
 * one word before and one word after each word are considered its context. Windows-size of 2 means that two words before
 * and two words after are considered its context (leading to 4 context words).
 * @param numberOfStopWords number of first most common words that are considered stop-words, so no data will be generated
 * for them (and they will not be written as context-words either).
 *
 *
 *
 */
class BuildNeighbors(
        private val wordFile: File,
        private val sentenceFile: File,
        private val numberOfWords: Int,
        private val outputFile: File,
        private val windowSize: Int,
        private val numberOfStopWords: Int
) : AutoCloseable
{

    /**
     * Generates the neighbors file.
     */
    fun build()
    {
        sentenceFile.useLines { lines ->
            var index = 0
            for ( line in lines)
            {
                write(line.split("\\s+".toRegex()).toTypedArray())

                ++index
                if (0==(index % 100)) { println(index) }
            }
            println(index)
        }
    }

    override fun close()
    {
        output.close()
    }


    private fun write(sentence: Array<String>)
    {
        if (sentence.size>=(2*windowSize+1))
        {
            for (index in windowSize until (sentence.size-windowSize))
            {
                if (wordMap.containsKey(sentence[index]))
                {
                    val wordId = wordMap.getOrDefault(sentence[index], 0)
                    if (wordId > numberOfStopWords)
                    {
                        for (contextIndex in (index - windowSize)..(index + windowSize))
                        {
                            if (contextIndex != index)
                            {
                                if (wordMap.containsKey(sentence[contextIndex]))
                                {
                                    val contextWordId = wordMap.getOrDefault(sentence[contextIndex], 0)
                                    if (contextWordId > numberOfStopWords)
                                    {
                                        if (OUTPUT_WORDS)
                                        {
                                            output.println("${sentence[index].asRegistered} ${sentence[contextIndex].asRegistered}")
                                        }
                                        else
                                        {
                                            output.println("$wordId $contextWordId")
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }


    private val String.asRegistered: String
        get() = if (wordMap.containsKey(this)) this else UNKNOWN

    private val wordMap: BidiMap<String, Int> = loadWords(wordFile, numberOfWords)
    private val output = outputFile.printWriter()
}


private fun loadWords(wordFile: File, numberOfWords: Int): BidiMap<String, Int>
{
    val ret = DualLinkedHashBidiMap<String, Int>()

    wordFile.useLines { lines->
        for ( (index,line) in (sequenceOf(UNKNOWN)+lines).withIndex())
        {
            if (index>numberOfWords) { break }
            ret.put(line, index)
        }
    }

    return ret
}